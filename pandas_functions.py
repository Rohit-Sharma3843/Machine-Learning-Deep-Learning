# -*- coding: utf-8 -*-
"""Pandas_functions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ucyQDGTvWAzGFKX6FGO4rSySYyDV90i8
"""

import pandas as pd
d={'Name' : ['Flanker','Felon','Fishbed','Foxbat'] ,'Age':[43,67,23,87]}
df=pd.DataFrame(d)
print(df)
# df=pd.read_excel("one.xlsx",sheet_name="Original")
# print(df)
df=pd.read_csv("customer_data.csv")
print(df)
print(df.columns) #Info about columns
print(df.shape) #Gives order of data
print("Info : ",df.info)
print("Age : ",df['Age']) #gives data of particular column
print("Age and Customer id : ",df[['Age','CustomerID']]) #gives data of multiple columns
print(df.head()) #gives first 5 values by default
print(df.head(10)) #gives first 10 values
print(df.tail()) #gives last 5 values by default
print(df.tail(10)) #gives last 10 values
print(df.describe()) #gives data i.e. min max count std mean
ndf=df.sort_values(by="Age",ascending=False)
print("Sorted : \n\n")
print(ndf)
print("Sorted : \n\n")
ndf=df.sort_values(by="Age",ascending=True)
print(ndf)
# ndf = df.sort_values(by=['Age', 'Name'], ascending=[True, True])
# print(ndf)
print(df.dtypes)
df.dtypes
print("Sorted : \n\n")
print(df.Age) #or write print(df['Age'])
print(type(df.Age))

import pandas as pd
df=pd.read_csv("customer_data.csv")
print(df[df["Age"]<30]) #accessing specific data
print("Some")
print(df["Age"]<30) #checks true or false
gp_data=df.groupby('Purchased')['Age'].sum()
print("-------------ONE-----------")
gp_data=df.groupby('Purchased')[['Age','SpendingScore']].sum()
print(gp_data)
print("-------------TWO-----------")
gp_data=df.groupby('Purchased')[['Age','SpendingScore']].mean()
print(gp_data)
gp_data=df.groupby('MembershipYears')[['Purchased','SpendingScore']].mean()
print(gp_data)

import pandas as pd
d1={'Length':[10,20,30,40,None,23,82,47,12,75],'Width':[34,None,42,5,5,3,None,12,None,8]}
df=pd.DataFrame(d1)
print("\n\n---------------1-----------------\n\n")
print(df)
df['Area']=df['Length']*df['Width'] #adding a new column in dataframe with name 'Area'
print("\n\n---------------2-----------------\n\n")
print(df)
df['Perimeter']=2*(df['Length']+df['Width']) #adding a new column in dataframe with 'Perimeter'
print("\n\n---------------3-----------------\n\n")
print(df)
df2=df.drop(columns=['Area'], inplace=False) #removing Area col from df and assgining it to df2
print("\n\n---------------4-----------------\n\n")
print(df2)
df.drop(columns=['Perimeter'], inplace=True) #removing Perimeter col from df and inplace changes are made
print("\n\n---------------5-----------------\n\n")
print(df)
print("\n\n---------------6-----------------\n\n")
print(df.info()) #prints number of non-null values
print("\n\n---------------7-----------------\n\n")
clean_data1=df.dropna() #drops all the non-null rows
clean_data1.info()
print(clean_data1)
print("\n\n---------------8-----------------\n\n")
clean_data2=df.dropna(axis=1) #drops all the non-null columns
print(clean_data2)
clean_data2.info()
print("\n\n---------------9-----------------\n\n")
clean_data3=df['Width'].fillna(value=df['Width'].mean(),inplace=False) #creates a new dataframe and inserts value in null values of Width column.Typically mean value is inserted
print(clean_data3)
print("\n\n---------------10-----------------\n\n")
clean_data4=df['Width'].fillna(value=df['Width'].median(),inplace=False) #creates a new dataframe and inserts value in null values of Width column.Typically mean value is inserted
print(clean_data4)
print("\n\n---------------11-----------------\n\n")
clean_data5=df['Width'].fillna(method='ffill',inplace=False) #does forward filling for none values
print(clean_data5)
print("\n\n---------------12-----------------\n\n")
clean_data6=df['Width'].fillna(method='bfill',inplace=False) #does backward filling for none values
print(clean_data6)
print("\n\n---------------12-----------------\n\n")
clean_data7=df['Width'].interpolate(method='linear',inplace=False) #does backward filling for none values
print(clean_data7)

import pandas as pd
d1={'Color':['Blue','Beige','Red','Yellow']}
d2={'Person':['a','b','c','d','e']}
df=pd.DataFrame(d1)
df1=pd.DataFrame(d2)
# ------------One Hot Encoding-----------

ohe1=pd.get_dummies(df['Color'])
ohe2=pd.get_dummies(df1['Person'])
print("\n\n---------------1-----------------\n\n")
print(ohe1)
print("\n\n---------------2-----------------\n\n")
print(ohe2)

# ------------Label Encoding-----------
from sklearn.preprocessing import LabelEncoder,OrdinalEncoder
le=LabelEncoder()
df3=le.fit_transform(df['Color'])
print("\n\n---------------3-----------------\n\n")
print(df3)


#------------Ordinal Encoding----------
oe=OrdinalEncoder()
df4=oe.fit_transform(df[['Color']])
print("\n\n---------------4-----------------\n\n")
print(df4)

#SPLITTING DATASET INTO TRAINING AND TEST DATASET
import sklearn
df=pd.read_csv("customer_data.csv")
# y=df['Purchased']
y=df.iloc[:,-1]
X=df.drop(columns=['Purchased'])
print("\n\n-------------------1------------------\n\n")
print(X)
print("\n\n-------------------2------------------\n\n")
print(X.info())
print("\n\n-------------------3------------------\n\n")
print(y)
print("\n\n-------------------4------------------\n\n")
print(y.info())
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
print("\n\n-------------------5------------------\n\n")
print(X_train)
print("\n\n-------------------6------------------\n\n")
print(X_test)
print("\n\n-------------------7------------------\n\n")

from sklearn.preprocessing import MinMaxScaler,StandardScaler
import pandas as pd
# df=pd.read_csv("customer_data.csv")
data={'Age':[12,45,65,34,8],'Income':[2000,40000,80000,100000,200]}
df=pd.DataFrame(data)
scaler1=StandardScaler()
scaler2=MinMaxScaler()
scaler1.fit(df[['Age','Income']])
df[['Age_scaled1','Income_Scaled2']]=scaler1.transform(df[['Age','Income']])
print("\n\n-------------------1------------------\n\n")
print(df)
print("\n\n-------------------2------------------\n\n")
scaler2.fit(df[['Age','Income']])
df[['Age_scaled2','Income_scaled2']]=scaler2.transform(df[['Age','Income']])
print(df)

import pandas as pd
import numpy as np
data={'Income':[2000,40000,80000,100000,20,100]}
df=pd.DataFrame(data)
df['Income_modified']=np.log(df['Income'])
print(df)

"""##OVERSAMPLING , SMOTE & UNDERSAMPLING"""

#------------------OVERSAMPLING , SMOTE & UNDERSAMPLING , Dimensions Reduction-----------------
import pandas as pd
df=pd.read_csv("customer_data.csv")
y=df.Purchased
print(y)
X=df.drop(columns=['Purchased'])
print(X)
from sklearn.decomposition import PCA,TruncatedSVD
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
scale=StandardScaler()
X_scaled=scale.fit_transform(X)
pca=PCA(n_components=1)
lda=LinearDiscriminantAnalysis(n_components=1)
X_pca=pca.fit_transform(X_scaled)
print(X_pca)
# pd.to_csv(X_pca,"one.csv")
# Convert the PCA output (which is a NumPy array) into a DataFrame first
X_pca_df = pd.DataFrame(X_pca, columns=["PCA_Component_1"])

# Now save it to a CSV file
X_pca_df.to_csv("one.csv", index=False)