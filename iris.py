# -*- coding: utf-8 -*-
"""IRIS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dsUQ3Msi8wDoBHZTVq14QYMfJ1oV03LT

##Importing required Libraries
"""

import pandas as py
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""##Exploring Data

"""

df=sns.load_dataset('iris')
print("\n\n-----------------1-----------------\n\n")
print(df.shape)
print(df.columns)
print("\n\n-----------------2-----------------\n\n")
print(df.info())
print("\n\n-----------------3-----------------\n\n")
print(df.describe())
print("\n\n-----------------4-----------------\n\n")
print(df.groupby('species').mean(),"\n\n")
print(df.head(7),"\n\n")
print(df.tail(5),"\n\n")
print("\n\n-----------------5-----------------\n\n")
print(df.groupby('petal_width')['sepal_length'].mean())

"""##Data Visualisation"""

print("\n\n-----------------6-----------------\n\n")
spcs=df['species']
spcs=spcs.value_counts()
print(spcs)
c=['r','g','b']
names=['setosa','versicolor','virginica']
plt.title("Species distribution")
plt.pie(spcs,labels=names,autopct="%.1f%%")
plt.show()
sp_len=df['sepal_length']
sp_wd=df['sepal_width']
ptl_len=df['petal_length']
ptl_wd=df['petal_width']
print("\n\n-----------------7-----------------\n\n")
plt.scatter(sp_len,sp_wd,color='r')
plt.scatter(ptl_len,ptl_wd,color='g')
plt.scatter(ptl_len,sp_wd,color='b')
plt.scatter(sp_len,ptl_wd,color='y')
plt.xlabel("Sepal length(r),Petal length(g),Petal width(b),Sepal width(y)")
plt.ylabel("Sepal width(r),Petal length(g),Petal width(b),Sepal width(y)")
plt.show()
print("\n\nPetal Length and Petal Width\n\n")
plt.plot(ptl_len,linestyle='--',color='m')
plt.plot(ptl_wd,linestyle='--',color='k')
plt.show()
print("\n\nSepal Length and Sepal Width\n\n")
plt.plot(sp_len,linestyle='--',color='g')
plt.plot(sp_wd,linestyle='--',color='y')
plt.show()

"""##Data Cleaning"""

dp_data=df[df.duplicated()]
print("\n\n-----------------8-----------------\n\n")
print(dp_data)
print("\n\n-----------------9-----------------\n\n")
df.drop_duplicates(inplace=True)
dp_data=df[df.duplicated()]
print(dp_data)

"""##Data Featuring"""

from sklearn.preprocessing import MinMaxScaler,StandardScaler
scaler=MinMaxScaler()
scaler.fit(df[['petal_length']])
print("\n\n-----------------10-----------------\n\n")
df[['petal_length']]=scaler.transform(df[['petal_length']])
ptl_len=df['petal_length']
plt.plot(ptl_len,linestyle='--',color='m')

"""##Encoding"""

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
print("\n\n-----------------11-----------------\n\n")
df['species']=le.fit_transform(df['species'])
print(df)
print("\n\n-----------------12-----------------\n\n")

"""##Train Test Data Splitting"""

from sklearn.model_selection import train_test_split
x=df.drop('species',axis=1)
y=df['species']
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
print("\n\n-----------------13-----------------\n\n")
print(x_train.shape)
print("\n\n-----------------14-----------------\n\n")
print(x_test.shape)
print("\n\n-----------------15-----------------\n\n")
print(y_train.shape)
print("\n\n-----------------16-----------------\n\n")
print(y_test.shape)

"""##Dimensional Reduction"""

from sklearn.decomposition import PCA,TruncatedSVD
pca=PCA(n_components=1)
print("\n\n-----------------17-----------------\n\n")
pca.fit(x_train)
x_train1d=pca.transform(x_train)
print(x_train1d)
print("\n\n-----------------18-----------------\n\n")
print(x_train1d.shape)

"""##Exporting Cleaned Data"""

x_train1d_df=py.DataFrame(x_train1d,columns=['Parameter'])
x_train1d_df.to_csv("x_train1d.csv",index=True)
print("\n\n-----------------19-----------------\n\n")
x_test1d=pca.transform(x_test)
print(x_test1d)